카글 커신러닝 플랫폼이랑 행사 참여 후기 

카글은 머신러닝 competition 플랫폼으로 작년에 구글이 인수를 했다. 

보면 어떤 문제를 푸는건지 정의가 되어있고 상금 학회초청 등등의 혜텍이 딸려 있는 등 꿀을 발라놨다. 
내부에는 트레이닝 데이터와 테스트 데이터가 주어지는데, 트레이닝 데이터로 학습을 하고 정답이 알려지지 않은 테스트 데이터를 예측을 해서 평가를 받는다. 리더보드에 가면 몇등했느지 볼 수 있고 문제 해결에 직접적인 답은 올릴 수 없지만 파일 관련 등등 의견을 나눌 수 있는 커뮤니티가 있다. 
하고 나면 메달을 주는데 메달을 갖고 랭킹을 매겨 놓기도 한다. 

보면 내가 데이터 셋을 갖고 있을 시 카글 호스트로 삼아서 대회를 개최할 수 있는 등으로 사용할 수 있다. 

과거엔 머신러닝 기만 문제들이 많았고 현재는 데이터를 엄청나게 많이 줘서 GPU를 쓸 수 밖에 없다거나 등등 

딜런은 Cdiscount image classfication challenge 에 참여했다. Cdiscount는 프랑스의 11번가같은 최대 인터넷 쇼핑몰이고 이거 상품을 분류하는 대회였다. 
1200만장 데이터에 5200개 카테고리였고, 데이터의 분포가 불균형이 엄청 심해서 몇몇 상품은 엄청 많고 대부분의 상품은 데이터가 10개~5개정도 밖에 없는 수준이었다. 그런데 이 친구들이 준 데이터를 보니 실제 데이터를 갖다 쓴 것 같아서 앞에 사진 많은 것들만 잘 분류를 해보자 라는 전략으로 갔다고 한다. 약간 competition 특화 전략.. 
중복된 이미지도 엄청나게 많았다. 해서 중복된거를 제거했더니 30퍼가 날아갔다. 그래서 학습 시간은 줄일 수 있었는데 보면 이렇게 줄인게 성능이 더 떨어지는데, 이유는 실제 데이터 역시 엄청난 중복을 포함하고 있어서 학습에서도 중복된 데이터들을 강조해서 학습을 해줘야 잘됐다~ 정도이다. 

DenseNet - 좀 더 많은 커넥션을 달아줘서 ~~~

SE 넷같은 경우 프리트레인 된 것이 없는데 이는 레즈넥스트의 데이터를 들고 오고 새로 추가된 브랜치 부분은 랜덤 이니셜로 설정해주어 학습을 진행했다. 구조가 달라지면 이 프리트레인 된 데이터가 도움이 되는가 하는 의문이 있지만 뭐 시렇ㅁ적으로는 ㄷ도움 되는 것 같다. 

Optimizer의 경우 SGD NAG Adam Nadam이 있는데 이중 Nadam이 가장 성능이 좋았다. 
Augmentation 도 골라서 바꿔가면서 했는데, 플립만 하는게 성능이 제일 좋았고 학습 속도랑 절충해서 확대는 하지 않는걸로. 
Label smoothing 이라는게 있는데 아웃풋 값을 0을 주는게 아니고 0.1처럼 작더라도 조금이라도 값을 주겠다는 방법이다. 이유는 이미지 데이터 자체에도 상당한 에러를 포함하고 있기 때문에 이런 방법으로 좀 더 높은 성능을 이끌어 낼 수 있다는 주장이 있다. 실제로 0.1로 뒀을 때가 가장 좋은 성능을 주었다. 
Drop out은 안하는게 좋았다. 

등등 이런 설정들을 조절해주다 보니 14개의 모델이 나왔고, 이걸 갖고 앙상블을 해서 결과를 내었다. 젤좋은걸 14번 하지 않는 이유는, 초기 시작 위치가 같다 보니까 서로 비슷한 로컬 옵티멀로 달릴 것이고, 각자 다른 모델들이 잘 표현하는 피쳐가 다르기 때문에 이렇게 다른 모델들을 포함해서 앙상블을 한다. 
젤좋은게 에폭 한번 도는데 14시간이 든다. 
앙상브ㅡㄹ의 경우 arithmetic mean과 geometric mean을 쓰는데 각가 어떻게 쓰는지 경우마다 다르다. 집중안해서 못들었다. 

MD5 hash 해서 이미지별로 해봤더니 트레이닝 데이터에 있는 이미지가 테스트에도 있는걸 알 수 있어서 룰링을 해주었다... 뭐 그런데 이걸 전체를 md5 hasing을 하는거보다 패치를 붙여서 부분부분 해주는게 이쪽 문제에 대해서는 성능이 더 좋을 수 있다고 한다. 

앙상블도 몇개를 하는게 더 좋은지 다를 수 있으니 1개 2개 4개 ... 22개까지 나눠서 실험을 해보았고 14개에 후처리를 해주는 것이 가장 좋은 성능을 냈다. private 는 test의 30퍼를 갖고 카글측에서 개인에게 공지하는 점수이고, 최종적으로 풀 테스트데이터를 갖고 하는게 public이다. 

0MQ를 쓰면 프로세싱간 통신에서 생기는 병목을 해결할 수 있는가보다?
Largemargin softmax - 요거 같은 이미지인데 레이블링이 다른 케이스가 있는 경우 마진이 발산해버리는 일이 생길 수 있기 때문에 안된게 아닐까 라고 생각. 
참고로 이런데서 나오는이미지에 한 이미지에 클래스가 여러개 나오는건 한 이미지에 여러개 상품이 들어있는 케이스가 있다. 

B-CNN 이란거도 있는데 이니셜라이제이션을 잘하면 B-CNN을 통한 이득이 줄어들 것이다 ㅏㄹ는 말이 논문에 있다. 

12Channel 

1등하신 분이 공개했는데, 이미지를 여러개 붙여서 사용하기도 했다. 이게 테스트 데이터가 이렇게 들어오기도 하고, 인풋부터 앙상블 데이터를 넣는 효과가 있다. 

그리고 이ㅑㅇ기ㅏㄱ 나왔다가 시도하지 않았던 OCR을 썼는데, 평가할 데이터가 없다 보니 딮러닝기반 OCR을 사용하면서 얻어진 feature를 갖다가 썼다고 한다. 
이사람은 모델들이 나온 피쳐들을 가지고 이걸 concate을 해서 다시 학습을 하는 모델을 만들었다. 이게 예전 대회에서도 나온듯 하다. 남들 score average를 하는걸 쟤네는 모델링을 한거.  

OCR같은걸 써보려 했는데 패스 



